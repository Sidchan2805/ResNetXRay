{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35809db1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mzipfile\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ZipFile\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5c0d7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "2    60361\n",
      "1    50328\n",
      "0     1431\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load metadata\n",
    "df = pd.read_csv(\"Data_Entry_2017.csv\")\n",
    "\n",
    "# Define classification logic\n",
    "def classify(label):\n",
    "    if label == \"No Finding\":\n",
    "        return 2\n",
    "    elif \"Pneumonia\" in label:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "df[\"Class\"] = df[\"Finding Labels\"].apply(classify)\n",
    "\n",
    "# Check class distribution\n",
    "print(df[\"Class\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0355f360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "0    1000\n",
      "1    1000\n",
      "2    1000\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sidch\\AppData\\Local\\Temp\\ipykernel_17368\\508140848.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=1000, random_state=42))\n"
     ]
    }
   ],
   "source": [
    "# Stratified sampling\n",
    "df_balanced = (\n",
    "    df.groupby(\"Class\", group_keys=False)\n",
    "    .apply(lambda x: x.sample(n=1000, random_state=42))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Check again\n",
    "print(df_balanced[\"Class\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "157cd7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: balanced_dataset.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Finding Labels</th>\n",
       "      <th>Follow-up #</th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Gender</th>\n",
       "      <th>View Position</th>\n",
       "      <th>OriginalImage[Width</th>\n",
       "      <th>Height]</th>\n",
       "      <th>OriginalImagePixelSpacing[x</th>\n",
       "      <th>y]</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002360_002.png</td>\n",
       "      <td>Pneumonia</td>\n",
       "      <td>2</td>\n",
       "      <td>2360</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>2048</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00022338_002.png</td>\n",
       "      <td>Atelectasis|Pneumonia</td>\n",
       "      <td>2</td>\n",
       "      <td>22338</td>\n",
       "      <td>60</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>2992</td>\n",
       "      <td>2991</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00010530_028.png</td>\n",
       "      <td>Edema|Infiltration|Pneumonia</td>\n",
       "      <td>28</td>\n",
       "      <td>10530</td>\n",
       "      <td>38</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>2658</td>\n",
       "      <td>2725</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00008043_002.png</td>\n",
       "      <td>Atelectasis|Pneumonia</td>\n",
       "      <td>2</td>\n",
       "      <td>8043</td>\n",
       "      <td>59</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>2366</td>\n",
       "      <td>2509</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00026560_010.png</td>\n",
       "      <td>Cardiomegaly|Consolidation|Pneumonia</td>\n",
       "      <td>10</td>\n",
       "      <td>26560</td>\n",
       "      <td>46</td>\n",
       "      <td>F</td>\n",
       "      <td>AP</td>\n",
       "      <td>3056</td>\n",
       "      <td>2544</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Image Index                        Finding Labels  Follow-up #  \\\n",
       "0  00002360_002.png                             Pneumonia            2   \n",
       "1  00022338_002.png                 Atelectasis|Pneumonia            2   \n",
       "2  00010530_028.png          Edema|Infiltration|Pneumonia           28   \n",
       "3  00008043_002.png                 Atelectasis|Pneumonia            2   \n",
       "4  00026560_010.png  Cardiomegaly|Consolidation|Pneumonia           10   \n",
       "\n",
       "   Patient ID  Patient Age Patient Gender View Position  OriginalImage[Width  \\\n",
       "0        2360           33              F            PA                 2048   \n",
       "1       22338           60              F            PA                 2992   \n",
       "2       10530           38              F            PA                 2658   \n",
       "3        8043           59              F            PA                 2366   \n",
       "4       26560           46              F            AP                 3056   \n",
       "\n",
       "   Height]  OriginalImagePixelSpacing[x     y]  Unnamed: 11  Class  \n",
       "0     2500                        0.171  0.171          NaN      0  \n",
       "1     2991                        0.143  0.143          NaN      0  \n",
       "2     2725                        0.143  0.143          NaN      0  \n",
       "3     2509                        0.143  0.143          NaN      0  \n",
       "4     2544                        0.139  0.139          NaN      0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced.to_csv(\"balanced_dataset.csv\", index=False)\n",
    "print(\"✅ Saved: balanced_dataset.csv\")\n",
    "df_balanced.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c990cf9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Train: {1: 700, 2: 700, 0: 700}\n",
      "✅ Val: {1: 150, 0: 150, 2: 150}\n",
      "✅ Test: {1: 150, 2: 150, 0: 150}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load the balanced dataset\n",
    "df = pd.read_csv(\"balanced_dataset.csv\")\n",
    "\n",
    "# First split into train (70%) and temp (30%)\n",
    "train_df, temp_df = train_test_split(\n",
    "    df, \n",
    "    test_size=0.3, \n",
    "    stratify=df[\"Class\"], \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Then split temp into val (15%) and test (15%)\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=0.5,\n",
    "    stratify=temp_df[\"Class\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Save the splits\n",
    "train_df.to_csv(\"train.csv\", index=False)\n",
    "val_df.to_csv(\"val.csv\", index=False)\n",
    "test_df.to_csv(\"test.csv\", index=False)\n",
    "\n",
    "print(\"✅ Train:\", train_df[\"Class\"].value_counts().to_dict())\n",
    "print(\"✅ Val:\", val_df[\"Class\"].value_counts().to_dict())\n",
    "print(\"✅ Test:\", test_df[\"Class\"].value_counts().to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5dff7fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Indexed 112120 total image files across all folders.\n",
      "\n",
      "📦 Processing train.csv...\n",
      "\n",
      "📦 Processing val.csv...\n",
      "\n",
      "📦 Processing test.csv...\n",
      "\n",
      "✅ Done!\n",
      "✅ Total images copied: 3000\n",
      "⚠️ Total missing files: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "# ✅ Step 1: Define your extracted image folders\n",
    "# Assuming folders are named images_001, images_002, ..., images_012\n",
    "image_folders = [f\"images_{i:03d}\" for i in range(1, 13)]\n",
    "\n",
    "# ✅ Step 2: Recursively index all available image files (even inside subfolders like 'images_001/images/')\n",
    "file_map = {}\n",
    "for base_folder in image_folders:\n",
    "    root = os.path.abspath(base_folder)\n",
    "    if not os.path.exists(root):\n",
    "        continue\n",
    "    for dirpath, _, filenames in os.walk(root):\n",
    "        for fname in filenames:\n",
    "            normalized = fname.strip().lower()\n",
    "            full_path = os.path.join(dirpath, fname)\n",
    "            file_map[normalized] = full_path\n",
    "\n",
    "print(f\"✅ Indexed {len(file_map)} total image files across all folders.\")\n",
    "\n",
    "# ✅ Step 3: Set class labels\n",
    "class_map = {\n",
    "    0: \"pneumonia\",\n",
    "    1: \"other\",\n",
    "    2: \"normal\"\n",
    "}\n",
    "\n",
    "# ✅ Step 4: Create output folder structure\n",
    "splits = [\"train\", \"val\", \"test\"]\n",
    "for split in splits:\n",
    "    for class_id, class_name in class_map.items():\n",
    "        os.makedirs(os.path.join(\"curated_data\", split, f\"class_{class_id}_{class_name}\"), exist_ok=True)\n",
    "\n",
    "# ✅ Step 5: Copy matching files from image folders to curated_data structure\n",
    "missing = 0\n",
    "copied = 0\n",
    "\n",
    "for split in splits:\n",
    "    print(f\"\\n📦 Processing {split}.csv...\")\n",
    "    df = pd.read_csv(f\"{split}.csv\")\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        raw_fname = row[\"Image Index\"]\n",
    "        normalized_fname = raw_fname.strip().lower()\n",
    "        class_id = row[\"Class\"]\n",
    "        class_folder = f\"class_{class_id}_{class_map[class_id]}\"\n",
    "        dest_path = os.path.join(\"curated_data\", split, class_folder, raw_fname)\n",
    "\n",
    "        if normalized_fname in file_map:\n",
    "            src_path = file_map[normalized_fname]\n",
    "            shutil.copyfile(src_path, dest_path)\n",
    "            copied += 1\n",
    "        else:\n",
    "            print(f\"⚠️ Missing: {raw_fname}\")\n",
    "            missing += 1\n",
    "\n",
    "print(f\"\\n✅ Done!\")\n",
    "print(f\"✅ Total images copied: {copied}\")\n",
    "print(f\"⚠️ Total missing files: {missing}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2dbf4cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder: images_001\n",
      "['images']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for folder in [\"images_001\", \"images_002\", \"images_003\"]:\n",
    "    if os.path.exists(folder):\n",
    "        print(f\"Folder: {folder}\")\n",
    "        print(os.listdir(folder)[:5])  # Print first 5 filenames\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa1a61cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Zipped successfully: pneumonia_curated.zip\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.make_archive(\"pneumonia_curated\", 'zip', \"curated_data\")\n",
    "print(\"✅ Zipped successfully: pneumonia_curated.zip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29695c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
